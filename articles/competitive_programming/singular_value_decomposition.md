# 特異値分解

特異値分解（Singular Value Decomposition, SVD）は、任意の実数行列や複素数行列を3つの行列の積に分解する線形代数の基本的な行列分解手法である。固有値分解が正方行列に対してのみ定義されるのに対し、特異値分解は任意のサイズの行列に適用可能であることが大きな特徴となっている。競技プログラミングにおいては、主成分分析、低ランク近似、擬似逆行列の計算などの場面で活用される。

特異値分解の理論的な重要性は、それが行列の本質的な構造を明らかにすることにある。任意の $m \times n$ 行列 $A$ は、3つの特別な性質を持つ行列の積として表現できる。この分解は一意に定まり、行列のランク、条件数、擬似逆行列など、多くの重要な性質を効率的に計算する手段を提供する。

## 数学的定義と基本性質

任意の $m \times n$ 実数行列 $A$ に対して、以下のような分解が存在する：

$$A = U\Sigma V^T$$

ここで、$U$ は $m \times m$ の直交行列、$V$ は $n \times n$ の直交行列、$\Sigma$ は $m \times n$ の対角行列である。$\Sigma$ の対角成分 $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$ を特異値と呼び、$r$ は行列 $A$ のランクである。直交行列の性質から $U^TU = I_m$、$V^TV = I_n$ が成り立つ。

```mermaid
graph LR
    A["行列 A (m×n)"] --> SVD["特異値分解"]
    SVD --> U["U (m×m)<br/>左特異ベクトル"]
    SVD --> Σ["Σ (m×n)<br/>特異値"]
    SVD --> VT["V^T (n×n)<br/>右特異ベクトル"]
    U --> PROD["積 UΣV^T"]
    Σ --> PROD
    VT --> PROD
    PROD --> A2["元の行列 A"]
```

特異値分解の存在性と一意性は、行列論の基本定理の一つである。任意の行列に対して特異値分解が存在することは、$A^TA$ と $AA^T$ が半正定値対称行列であることから導かれる。これらの行列の固有値は非負実数であり、その平方根が特異値となる。

## 幾何学的解釈

特異値分解は、線形変換の幾何学的な構造を明らかにする。$m \times n$ 行列 $A$ による線形変換 $x \mapsto Ax$ は、以下の3つの変換の合成として理解できる：

1. **$V^T$ による回転**：$n$ 次元空間における回転または反転
2. **$\Sigma$ によるスケーリング**：各軸方向への伸縮
3. **$U$ による回転**：$m$ 次元空間における回転または反転

この解釈により、任意の線形変換は「回転→スケーリング→回転」という単純な操作の組み合わせとして表現できることがわかる。特に、$n$ 次元単位球は、この変換により $m$ 次元空間の楕円体に写像される。この楕円体の主軸の長さが特異値に対応する。

```mermaid
graph TD
    S1["n次元単位球"] -->|"V^T: 回転"| S2["回転後の単位球"]
    S2 -->|"Σ: スケーリング"| S3["楕円体"]
    S3 -->|"U: 回転"| S4["m次元空間の楕円体"]
    
    subgraph "変換の流れ"
        S1
        S2
        S3
        S4
    end
```

## 特異値と特異ベクトルの計算

特異値分解を計算する基本的なアプローチは、$A^TA$ と $AA^T$ の固有値問題に帰着させることである。具体的には：

$$A^TA = V\Sigma^T\Sigma V^T$$
$$AA^T = U\Sigma\Sigma^T U^T$$

ここで、$\Sigma^T\Sigma$ は $n \times n$ の対角行列であり、その対角成分は $\sigma_i^2$ である。同様に、$\Sigma\Sigma^T$ は $m \times m$ の対角行列となる。したがって、$V$ の列ベクトルは $A^TA$ の固有ベクトル、$U$ の列ベクトルは $AA^T$ の固有ベクトルとなる。

実際の数値計算では、この直接的なアプローチは数値的に不安定である。$A^TA$ の条件数は $A$ の条件数の2乗となるため、誤差が増幅される。そのため、実用的なアルゴリズムでは、行列を直接扱う手法が採用される。

## Golub-Kahan二段階アルゴリズム

現代的な特異値分解アルゴリズムの標準は、Golub-Kahanによる二段階アルゴリズムである[^1]。このアルゴリズムは以下の2つのステップから構成される：

[^1]: Golub, G. H., & Kahan, W. (1965). "Calculating the singular values and pseudo-inverse of a matrix". Journal of the Society for Industrial and Applied Mathematics, Series B: Numerical Analysis, 2(2), 205-224.

### 第1段階：二重対角化

Householder変換を用いて、行列 $A$ を二重対角行列 $B$ に変換する：

$$A = P_1BP_2^T$$

ここで、$P_1$ と $P_2$ は直交行列である。二重対角行列とは、主対角成分と第一優対角成分のみが非零の行列である。この変換は $O(mn^2)$ の計算量で実行できる。

### 第2段階：二重対角行列の特異値分解

二重対角行列 $B$ に対して、QRアルゴリズムの変種を適用し、対角行列に収束させる。このプロセスでは、Givens回転を用いて非対角成分を徐々に小さくしていく。収束後、対角成分が特異値となる。

```mermaid
flowchart TB
    A["元の行列 A"] --> H1["Householder変換<br/>(左から)"]
    H1 --> B1["部分的に二重対角化"]
    B1 --> H2["Householder変換<br/>(右から)"]
    H2 --> B["二重対角行列 B"]
    B --> QR["QRアルゴリズム<br/>(反復)"]
    QR --> D["対角行列<br/>(特異値)"]
    D --> SVD["完全な特異値分解"]
```

## 数値的安定性と計算精度

特異値分解の数値計算において重要な考慮事項は、アルゴリズムの数値的安定性である。特に小さな特異値の計算では、丸め誤差の影響が顕著になる。IEEE倍精度浮動小数点数を使用する場合、相対誤差は通常 $O(\epsilon \kappa(A))$ 程度となる。ここで、$\epsilon$ は機械精度（約 $2.2 \times 10^{-16}$）、$\kappa(A) = \sigma_{\max}/\sigma_{\min}$ は条件数である。

数値的な安定性を確保するために、以下の技術が用いられる：

**シフト戦略**：QRアルゴリズムの収束を加速するため、適切なシフトを選択する。Wilkinsonシフトが標準的に使用される。これは、末尾の $2 \times 2$ 部分行列の固有値に基づいてシフト量を決定する方法である。

**デフレーション**：収束した特異値を分離し、問題のサイズを段階的に縮小する。特異値が十分小さくなった場合や、優対角成分が機械精度以下になった場合に、行列を分割する。

**暗黙的QRステップ**：明示的にQR分解を計算する代わりに、Givens回転の列として暗黙的に実行する。これにより、数値的安定性が向上し、計算量も削減される。

## 擬似逆行列と最小二乗問題

特異値分解の重要な応用の一つは、擬似逆行列（Moore-Penrose逆行列）の計算である。行列 $A$ の擬似逆行列 $A^+$ は、特異値分解を用いて以下のように表現される：

$$A^+ = V\Sigma^+ U^T$$

ここで、$\Sigma^+$ は $\Sigma$ の擬似逆行列であり、非零の特異値の逆数を対角成分とする $n \times m$ 行列である。擬似逆行列は、過決定系や劣決定系の線形方程式 $Ax = b$ の最小二乗解を与える：

$$x = A^+b$$

この解は、$\|Ax - b\|_2$ を最小化し、かつその中で $\|x\|_2$ が最小となる唯一の解である。

競技プログラミングにおいて、最小二乗問題は回帰分析、曲線フィッティング、信号処理などの文脈で現れる。特異値分解を用いることで、数値的に安定した解法が得られる。特に、条件数が大きい（ill-conditioned）問題では、通常の正規方程式 $(A^TA)x = A^Tb$ を解く方法よりも優れている。

## 低ランク近似と圧縮

特異値分解のもう一つの重要な応用は、行列の低ランク近似である。Eckart-Youngの定理[^2]によれば、ランク $k$ の行列による最良近似は、最大の $k$ 個の特異値に対応する成分のみを保持することで得られる：

[^2]: Eckart, C., & Young, G. (1936). "The approximation of one matrix by another of lower rank". Psychometrika, 1(3), 211-218.

$$A_k = \sum_{i=1}^k \sigma_i u_i v_i^T$$

ここで、$u_i$ と $v_i$ はそれぞれ $U$ と $V$ の $i$ 番目の列ベクトルである。この近似の誤差は、Frobenius ノルムおよびスペクトルノルムの両方で最小となる：

$$\|A - A_k\|_F = \sqrt{\sum_{i=k+1}^r \sigma_i^2}$$
$$\|A - A_k\|_2 = \sigma_{k+1}$$

この性質は、データ圧縮、ノイズ除去、次元削減などに広く応用される。競技プログラミングでは、大規模な行列を扱う問題において、メモリ使用量を削減しながら近似的な計算を行う手法として有用である。

```mermaid
graph LR
    A["元の行列 A<br/>(m×n, ランクr)"] --> SVD["特異値分解"]
    SVD --> K["上位k個の<br/>特異値を選択"]
    K --> AK["近似行列 A_k<br/>(m×n, ランクk)"]
    
    subgraph "圧縮効果"
        O1["元: mn個の要素"]
        O2["圧縮後: k(m+n+1)個"]
    end
```

## 主成分分析との関係

主成分分析（Principal Component Analysis, PCA）は、特異値分解と密接に関連している。データ行列 $X$ （各行がサンプル、各列が特徴量）に対して、中心化した行列 $\tilde{X} = X - \bar{X}$ の特異値分解を考える：

$$\tilde{X} = U\Sigma V^T$$

このとき、$V$ の列ベクトルが主成分方向、$U\Sigma$ の列ベクトルが主成分スコアとなる。分散共分散行列 $C = \frac{1}{n-1}\tilde{X}^T\tilde{X}$ の固有ベクトルは $V$ の列ベクトルと一致し、固有値は $\frac{\sigma_i^2}{n-1}$ となる。

競技プログラミングにおいて、PCAは高次元データの可視化、特徴抽出、異常検知などの問題で使用される。特異値分解を用いることで、共分散行列を明示的に計算することなく、数値的に安定した方法でPCAを実行できる。

## 実装上の考慮事項

競技プログラミングにおいて特異値分解を実装する際には、以下の点を考慮する必要がある：

**計算量とメモリ使用量**：完全な特異値分解の計算量は $O(\min(m^2n, mn^2))$ である。大規模な行列に対しては、必要な特異値・特異ベクトルのみを計算する部分的な分解を検討すべきである。Arnoldi法やLanczos法などの反復法を用いることで、最大の数個の特異値のみを効率的に計算できる。

**疎行列への対応**：疎行列に対しては、密行列用のアルゴリズムは非効率である。ARPACK[^3]などの疎行列用ライブラリでは、行列-ベクトル積のみを用いて特異値を計算する手法が実装されている。

[^3]: Lehoucq, R. B., Sorensen, D. C., & Yang, C. (1998). "ARPACK users' guide: solution of large-scale eigenvalue problems with implicitly restarted Arnoldi methods". SIAM.

**並列化**：特異値分解の各段階は並列化可能である。特に、Householder変換や行列積の計算は、BLASレベル3の演算として効率的に並列実行できる。競技プログラミングの制約下では単一スレッドでの実行が前提となることが多いが、SIMD命令を活用した最適化は可能である。

## 特殊な構造を持つ行列

特定の構造を持つ行列に対しては、より効率的な特異値分解アルゴリズムが存在する：

**対称行列**：実対称行列の特異値分解は、固有値分解と本質的に同じである。特異値は固有値の絶対値となり、特異ベクトルは固有ベクトルから構成される。対称性を利用することで、計算量を約半分に削減できる。

**帯行列**：帯幅が小さい帯行列に対しては、二重対角化の過程で帯構造が保存される。これにより、メモリ使用量と計算量の両方を大幅に削減できる。

**Hankel行列・Toeplitz行列**：これらの構造行列に対しては、高速アルゴリズムが開発されている。FFTを用いることで、$O(n^2 \log n)$ の計算量で近似的な特異値分解を計算できる。

## 数値例による理解

具体的な数値例を通じて、特異値分解の挙動を理解することは重要である。以下の $3 \times 2$ 行列を考える：

$$A = \begin{pmatrix}
1 & 2 \\
3 & 4 \\
5 & 6
\end{pmatrix}$$

この行列の特異値分解は：

$$U \approx \begin{pmatrix}
-0.2298 & 0.8835 & 0.4082 \\
-0.5247 & 0.2408 & -0.8165 \\
-0.8196 & -0.4019 & 0.4082
\end{pmatrix}$$

$$\Sigma \approx \begin{pmatrix}
9.5255 & 0 \\
0 & 0.5143 \\
0 & 0
\end{pmatrix}$$

$$V \approx \begin{pmatrix}
-0.6196 & -0.7849 \\
-0.7849 & 0.6196
\end{pmatrix}$$

特異値 $\sigma_1 \approx 9.5255$ と $\sigma_2 \approx 0.5143$ の比は約18.5であり、この行列が数値的にランク1に近いことを示している。実際、ランク1近似 $A_1 = \sigma_1 u_1 v_1^T$ は元の行列を良く近似する。

## 計算の検証とデバッグ

特異値分解の実装をデバッグする際には、以下の性質を検証することが有用である：

**直交性の確認**：$U^TU = I$ および $V^TV = I$ が数値精度の範囲内で成立することを確認する。

**再構成誤差**：$\|A - U\Sigma V^T\|_F$ が機械精度のオーダーであることを確認する。

**特異値の非負性と降順**：$\sigma_1 \geq \sigma_2 \geq \cdots \geq 0$ が成立することを確認する。

**ランクの一致**：非零特異値の個数が、ガウス消去法などで計算したランクと一致することを確認する。

## 安定性解析と誤差評価

特異値分解の数値的安定性は、後退誤差解析により理論的に保証されている。計算された分解 $\hat{U}\hat{\Sigma}\hat{V}^T$ に対して、以下が成立する：

$$\hat{U}\hat{\Sigma}\hat{V}^T = A + E$$

ここで、誤差行列 $E$ は $\|E\|_F \leq c\epsilon\|A\|_F$ を満たす。定数 $c$ は問題のサイズに依存するが、通常は $O(mn)$ 程度である。

個々の特異値の相対誤差は、その大きさと周囲の特異値との間隔に依存する。大きな特異値ほど相対誤差が小さく、クラスター化した特異値は個別には正確に計算できない可能性がある。しかし、クラスター全体としての不変部分空間は正確に計算される。

## 拡張と一般化

特異値分解の概念は、様々な方向に拡張されている：

**一般化特異値分解（GSVD）**：2つの行列 $A$ と $B$ の同時分解であり、正則化問題や制約付き最小二乗問題に応用される。

**高階特異値分解（HOSVD）**：テンソル（多次元配列）への拡張であり、各モードに対する直交変換の組み合わせとして定義される。

**複素特異値分解**：複素行列に対しては、転置の代わりにエルミート共役を用いる。基本的な性質と計算手法は実数の場合と同様である。

これらの拡張は、より複雑な問題設定において特異値分解の概念を適用することを可能にする。競技プログラミングでは、多次元データの解析や複素信号処理の問題で活用される可能性がある。

## 競技プログラミングにおける具体的応用

特異値分解は、競技プログラミングの様々な問題カテゴリで活用される。以下、具体的な応用例を詳述する。

### 画像圧縮問題

画像を行列として表現し、低ランク近似により圧縮する問題は、特異値分解の典型的な応用である。グレースケール画像を $m \times n$ の行列 $A$ として表現し、上位 $k$ 個の特異値による近似 $A_k$ を計算することで、画像品質を保ちながらデータ量を削減できる。

圧縮率は $(m \times n) / (k(m + n + 1))$ で評価される。例えば、$512 \times 512$ の画像に対して $k = 50$ とすると、圧縮率は約5.0となる。この際、視覚的な品質を評価するPSNR（Peak Signal-to-Noise Ratio）は以下で計算される：

$$\text{PSNR} = 10 \log_{10} \left( \frac{255^2}{\text{MSE}} \right)$$

ここで、MSE（Mean Squared Error）は $\|A - A_k\|_F^2 / (mn)$ である。

### 推薦システムとコラボレーティブフィルタリング

ユーザーとアイテムの評価行列に対して特異値分解を適用することで、欠損値の予測が可能となる。$m$ 人のユーザーと $n$ 個のアイテムからなる評価行列 $R$ に対して、低ランク近似を用いて未評価のエントリを予測する。

この手法は、Netflix Prize競技会で広く使用された。評価行列の特異値分解 $R \approx U\Sigma V^T$ において、$U$ の行はユーザーの潜在的な嗜好を、$V$ の行はアイテムの潜在的な特徴を表現する。予測値は以下で計算される：

$$\hat{r}_{ij} = \sum_{k=1}^r \sigma_k u_{ik} v_{jk}$$

### 文書分類と潜在意味解析

文書-単語行列に対する特異値分解は、潜在意味解析（Latent Semantic Analysis, LSA）として知られる。$m$ 個の文書と $n$ 個の単語からなる行列 $X$ に対して、低ランク近似を適用することで、同義語や多義語の問題を緩和できる。

変換後の空間では、意味的に類似した文書や単語が近くに配置される。文書間の類似度は、低次元表現でのコサイン類似度により計算される：

$$\text{similarity}(d_i, d_j) = \frac{(U\Sigma)_i \cdot (U\Sigma)_j}{\|(U\Sigma)_i\| \|(U\Sigma)_j\|}$$

## 高度な実装技術

### ブロック化とキャッシュ効率

大規模行列に対する特異値分解では、キャッシュ効率が性能に大きく影響する。ブロック化アルゴリズムは、行列をサブブロックに分割し、各ブロックがキャッシュに収まるように処理する。

Householder変換のブロック化では、複数のベクトルをまとめて処理する。$k$ 個のHouseholderベクトル $v_1, \ldots, v_k$ に対して、累積変換行列 $Q = I - VTV^T$ を構成する。ここで、$V = [v_1, \ldots, v_k]$、$T$ は上三角行列である。

### 反復的改良と誤差解析

計算された特異値分解の精度を向上させるため、反復的改良が適用される。残差 $R = A - U\Sigma V^T$ に対して、補正項 $\Delta U$、$\Delta \Sigma$、$\Delta V$ を計算し、解を更新する。

Newton-Schulz反復は、直交性を保ちながら精度を改善する手法である：

$$U_{k+1} = \frac{3}{2}U_k - \frac{1}{2}U_k U_k^T U_k$$

この反復は二次収束し、数回の反復で機械精度に達する。

### 並列アルゴリズムの詳細

分散メモリ環境での特異値分解は、ScaLAPACKなどのライブラリで実装されている。2次元ブロック巡回分散により、行列を複数のプロセッサに分散させる。

通信パターンの最適化は重要である。Householder変換では、ベクトルのブロードキャストと行列更新の削減操作が必要となる。通信と計算のオーバーラップにより、スケーラビリティを向上させる。

## Lanczos法による大規模疎行列の特異値分解

大規模疎行列に対しては、Lanczos法が効率的である。この反復法は、行列-ベクトル積のみを使用し、最大の数個の特異値を計算する。

Lanczos過程は、三重対角行列 $T_k$ を生成する：

$$AV_k = U_k T_k + \beta_k u_{k+1} e_k^T$$
$$A^T U_k = V_k T_k^T + \alpha_k v_{k+1} e_k^T$$

ここで、$V_k = [v_1, \ldots, v_k]$ と $U_k = [u_1, \ldots, u_k]$ は正規直交基底である。$T_k$ の特異値は $A$ の特異値の近似となる。

### 再直交化戦略

有限精度演算では、Lanczosベクトルの直交性が失われる。完全再直交化は、各ステップで全ての以前のベクトルに対して直交化を行う：

$$\tilde{v}_{k+1} = v_{k+1} - \sum_{i=1}^k (v_i^T v_{k+1}) v_i$$

選択的再直交化は、直交性の損失を監視し、必要な場合のみ再直交化を実行する。Simonの基準では、$|v_i^T v_{k+1}| > \sqrt{\epsilon}$ の場合に再直交化を行う。

## 構造化行列の特殊アルゴリズム

### Toeplitz行列の高速特異値分解

Toeplitz行列 $T$ は、各対角線上で要素が一定の行列である。この構造を利用した高速アルゴリズムが開発されている。

変位構造を用いたアプローチでは、$T$ を低ランク行列の和として表現する：

$$T - ZTZ^T = GG^T - HH^T$$

ここで、$Z$ はシフト行列、$G$ と $H$ は低ランク行列である。この表現を用いて、$O(n^2)$ の計算量で近似的な特異値分解を計算できる。

### 階層的行列の特異値分解

階層的行列（H-matrix）は、適切に並べ替えることで、ブロックが低ランクまたは小さなサイズになる行列である。物理シミュレーションや積分方程式で頻繁に現れる。

階層的特異値分解は、各ブロックに対して個別に分解を計算し、それらを組み合わせる。低ランクブロックには打ち切り特異値分解を、小さなブロックには通常の特異値分解を適用する。

## 誤差解析の詳細

### 前進誤差と後退誤差

特異値分解の誤差解析では、前進誤差と後退誤差の両方を考慮する。前進誤差は計算結果と真の値の差であり、後退誤差は計算結果が厳密解となるような摂動の大きさである。

Wedinの定理は、特異値と特異ベクトルの摂動に関する基本的な結果である。行列 $A$ と $\tilde{A} = A + E$ に対して、対応する特異値 $\sigma_i$ と $\tilde{\sigma}_i$ の差は以下で評価される：

$$|\sigma_i - \tilde{\sigma}_i| \leq \|E\|_2$$

特異ベクトルの摂動は、特異値の間隔に依存する。間隔が狭い場合、特異ベクトルは敏感に変化する。

### 条件数と感度分析

特異値の条件数は、その計算の感度を示す。特異値 $\sigma_i$ の条件数は：

$$\kappa(\sigma_i) = \frac{\sqrt{1 + \tan^2 \theta_U + \tan^2 \theta_V}}{\min_{j \neq i} |\sigma_i - \sigma_j| / \sigma_i}$$

ここで、$\theta_U$ と $\theta_V$ は左右の特異部分空間の主角である。

## 応用アルゴリズムの実装詳細

### 動的モード分解への応用

動的モード分解（Dynamic Mode Decomposition, DMD）は、時系列データから動的システムの固有モードを抽出する手法である。データ行列 $X = [x_1, \ldots, x_{m-1}]$ と $Y = [x_2, \ldots, x_m]$ に対して、線形作用素 $A$ を $Y = AX$ として近似する。

特異値分解 $X = U\Sigma V^T$ を用いて、$A$ の低ランク表現を計算する：

$$\tilde{A} = U^T Y V \Sigma^{-1}$$

$\tilde{A}$ の固有値と固有ベクトルから、システムの動的モードが得られる。

### ランダム化特異値分解

ランダム化アルゴリズムは、大規模行列の近似的な特異値分解を高速に計算する。基本的なアイデアは、ランダムサンプリングにより行列の作用を捉えることである。

アルゴリズムの概要：
1. ランダム行列 $\Omega \in \mathbb{R}^{n \times (k+p)}$ を生成
2. $Y = A\Omega$ を計算
3. $Y$ の正規直交基底 $Q$ を計算（QR分解）
4. $B = Q^T A$ を計算
5. $B$ の特異値分解 $B = \hat{U}\Sigma V^T$ を計算
6. $U = Q\hat{U}$ として、$A \approx U\Sigma V^T$ を得る

オーバーサンプリングパラメータ $p$ は通常5〜10程度に設定される。パワー反復により精度を向上させることができる：

$$Y = (AA^T)^q A\Omega$$

## 数値実験と性能評価

### ベンチマーク問題

特異値分解の実装を評価するための標準的なベンチマーク問題には以下がある：

**Kahan行列**：条件数が理論値と計算値で大きく異なる可能性がある行列。数値的な困難さを評価するのに適している。

**Läuchli行列**：小さなパラメータ $\epsilon$ に対して、特異値が $1$ と $\epsilon$ に集中する行列。特異値の分離を評価する。

**ランダム行列**：指定した特異値分布を持つランダム行列。一般的な性能を評価する。

### 性能プロファイル

異なるアルゴリズムの性能を比較するため、性能プロファイルが使用される。各問題に対する相対的な実行時間をプロットし、アルゴリズムの頑健性を評価する。

メモリ使用量、精度、実行時間のトレードオフを考慮した多目的最適化も重要である。Paretoフロントにより、最適なアルゴリズムパラメータを選択する。

## 最新の研究動向

### テンソル特異値分解

高次元データの解析において、テンソル（多次元配列）の特異値分解が注目されている。Tucker分解やCANDECOMP/PARAFAC分解など、様々な分解手法が提案されている。

テンソルトレイン分解は、高次元テンソルを低ランクコアの連鎖として表現する：

$$\mathcal{A}(i_1, \ldots, i_d) = G_1(i_1) G_2(i_2) \cdots G_d(i_d)$$

ここで、$G_k$ は3階テンソル（最初と最後は行列）である。

### 量子アルゴリズム

量子コンピュータによる特異値分解の高速化が研究されている。Harrow-Hassidim-Lloydアルゴリズムの拡張により、特定の条件下で指数的な高速化が可能である。

量子位相推定を用いて、行列の特異値を量子状態の位相として抽出する。ただし、現在の量子コンピュータのノイズレベルでは、実用的なサイズの問題への適用は困難である。

特異値分解は、線形代数の中核的な技術として、理論と実践の両面で重要な役割を果たしている。その幾何学的な直観、数値的な安定性、幅広い応用可能性により、競技プログラミングにおいても強力なツールとなる。効率的な実装と適切な応用により、複雑な問題を優雅に解決することができる。今後も、大規模データ解析、機械学習、科学計算の発展とともに、特異値分解の重要性はさらに増していくであろう。